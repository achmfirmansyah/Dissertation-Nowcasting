{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMhslsCUBk/sDYKidE3qZwZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"HhdX64KLJ954","executionInfo":{"status":"ok","timestamp":1685710664804,"user_tz":-60,"elapsed":3781,"user":{"displayName":"Achmad Firmansyah","userId":"16248168358056255671"}}},"outputs":[],"source":["import os\n","import torch\n","from torch import nn\n","from torch.nn import functional as F"]},{"cell_type":"code","source":["convlstm_encoder_params = [\n","    [\n","        OrderedDict({'conv1_leaky_1': [1, 8, 7, 5, 1]}),\n","        OrderedDict({'conv2_leaky_1': [64, 192, 5, 3, 1]}),\n","        OrderedDict({'conv3_leaky_1': [192, 192, 3, 2, 1]}),\n","    ],\n","\n","    [\n","        ConvLSTM(input_channel=8, num_filter=64, b_h_w=(batch_size, 96, 96),\n","                 kernel_size=3, stride=1, padding=1),\n","        ConvLSTM(input_channel=192, num_filter=192, b_h_w=(batch_size, 32, 32),\n","                 kernel_size=3, stride=1, padding=1),\n","        ConvLSTM(input_channel=192, num_filter=192, b_h_w=(batch_size, 16, 16),\n","                 kernel_size=3, stride=1, padding=1),\n","    ]\n","]\n","for index, (params, rnn) in enumerate(zip(subnets, rnns), 1):"],"metadata":{"id":"YW4kR-zzeBN6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class ConvLSTM(nn.Module):\n","  \"\"\"\n","  Class representing ConvLSTM layer based on Xingjian Shi: \"Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\"\n","\n","  Adapted from https://github.com/Hzzone/Precipitation-Nowcasting/blob/master/nowcasting/models/convLSTM.py\n","\n","  \"\"\"\n","  def __init__(self, input_channel, num_filter, b_h_w, kernel_size, stride=1, padding=1):\n","    \"\"\"\n","    Initiate the ConvLSTM layer\n","\n","    '''\n","    Parameters\n","    ----------\n","    input_channel: int \n","      the size of input\n","    num_filter: int\n","      number of filter used in the layer represent the time frame\n","    kernel_size: int\n","      kernel size\n","    stride: int\n","      stride\n","    padding: int\n","      padding\n","    \"\"\"\n","    super().__init__()\n","    self._conv = nn.Conv2d(in_channels=input_channel + num_filter,\n","                           out_channels=num_filter*4, #multiply with 4 since for i=>input, h=>hidden state, c=>memory, f=>forgotten layer\n","                           kernel_size=kernel_size,\n","                           stride=stride,\n","                           padding=padding)\n","    self._batch_size, self._state_height, self._state_width = b_h_w\n","    # Iniate the weight equals to 0.\n","    self.Wci = nn.Parameter(torch.zeros(1, num_filter, self._state_height, self._state_width))\n","    self.Wcf = nn.Parameter(torch.zeros(1, num_filter, self._state_height, self._state_width))\n","    self.Wco = nn.Parameter(torch.zeros(1, num_filter, self._state_height, self._state_width))\n","\n","    \n","    self._input_channel = input_channel\n","    self._num_filter = num_filter\n","\n","    # inputs: S*B*C*H*W\n","    # where S represent\n","  def forward(self, inputs=None, states=None, seq_len=cfg.HKO.BENCHMARK.IN_LEN):\n","\n","        if states is None:\n","            c = torch.zeros((inputs.size(1), self._num_filter, self._state_height,\n","                                  self._state_width), dtype=torch.float).to(cfg.GLOBAL.DEVICE)\n","            h = torch.zeros((inputs.size(1), self._num_filter, self._state_height,\n","                             self._state_width), dtype=torch.float).to(cfg.GLOBAL.DEVICE)\n","        else:\n","            h, c = states\n","\n","        outputs = []\n","        for index in range(seq_len):\n","            # initial inputs\n","            if inputs is None:\n","                x = torch.zeros((h.size(0), self._input_channel, self._state_height,\n","                                      self._state_width), dtype=torch.float).to(cfg.GLOBAL.DEVICE)\n","            else:\n","                x = inputs[index, ...]\n","            cat_x = torch.cat([x, h], dim=1)\n","            conv_x = self._conv(cat_x)\n","\n","            i, f, tmp_c, o = torch.chunk(conv_x, 4, dim=1)\n","\n","            i = torch.sigmoid(i+self.Wci*c)\n","            f = torch.sigmoid(f+self.Wcf*c)\n","            c = f*c + i*torch.tanh(tmp_c)\n","            o = torch.sigmoid(o+self.Wco*c)\n","            h = o*torch.tanh(c)\n","            outputs.append(h)\n","        return torch.stack(outputs), (h, c)"],"metadata":{"id":"GoXVvIZAJ_La"},"execution_count":null,"outputs":[]}]}