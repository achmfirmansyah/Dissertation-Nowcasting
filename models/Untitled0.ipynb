{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOr9W+XbQPWRvsRjAZ7idQg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import numpy as np\n","from tqdm import tqdm"],"metadata":{"id":"JrCRNO6VLskv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6NFDI9tQLXUm"},"outputs":[],"source":["def train_and_test(encoder_forecaster, \n","                   optimizer, criterion, lr_scheduler, batch_size, \n","                   max_iterations, test_iteration_interval, test_and_save_checkpoint_iterations, \n","                   folder_name, probToPixel=None):\n","    # HKO-7 evaluater and dataloader\n","    IN_LEN = cfg.HKO.BENCHMARK.IN_LEN\n","    OUT_LEN = cfg.HKO.BENCHMARK.OUT_LEN\n","    evaluater = HKOEvaluation(seq_len=OUT_LEN, use_central=False)\n","    train_hko_iter = HKOIterator(pd_path=cfg.HKO_PD.RAINY_TRAIN,\n","                                     sample_mode=\"random\",\n","                                     seq_len=IN_LEN+OUT_LEN)\n","\n","    valid_hko_iter = HKOIterator(pd_path=cfg.HKO_PD.RAINY_VALID,\n","                                     sample_mode=\"sequent\",\n","                                     seq_len=IN_LEN+OUT_LEN,\n","                                     stride=cfg.HKO.BENCHMARK.STRIDE)\n","\n","    train_loss = 0.0\n","    save_dir = osp.join(cfg.GLOBAL.MODEL_SAVE_DIR, folder_name)\n","    if os.path.exists(save_dir):\n","        shutil.rmtree(save_dir)\n","    os.mkdir(save_dir)\n","    model_save_dir = osp.join(save_dir, 'models')\n","    log_dir = osp.join(save_dir, 'logs')\n","    all_scalars_file_name = osp.join(save_dir, \"all_scalars.json\")\n","    pkl_save_dir = osp.join(save_dir, 'pkl')\n","    if osp.exists(all_scalars_file_name):\n","        os.remove(all_scalars_file_name)\n","    if osp.exists(log_dir):\n","        shutil.rmtree(log_dir)\n","    if osp.exists(model_save_dir):\n","        shutil.rmtree(model_save_dir)\n","    os.mkdir(model_save_dir)\n","\n","    writer = SummaryWriter(log_dir)\n","\n","    for itera in tqdm(range(1, max_iterations+1)):\n","        lr_scheduler.step()\n","        train_batch, train_mask, sample_datetimes, _ = \\\n","            train_hko_iter.sample(batch_size=batch_size)\n","        train_batch = torch.from_numpy(train_batch.astype(np.float32)).to(cfg.GLOBAL.DEVICE) / 255.0\n","        train_data = train_batch[:IN_LEN, ...]\n","        train_label = train_batch[IN_LEN:IN_LEN + OUT_LEN, ...]\n","        mask = torch.from_numpy(train_mask[IN_LEN:IN_LEN + OUT_LEN, ...].astype(int)).to(cfg.GLOBAL.DEVICE)\n","\n","        encoder_forecaster.train()\n","        optimizer.zero_grad()\n","        output = encoder_forecaster(train_data)\n","        loss = criterion(output, train_label, mask)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_value_(encoder_forecaster.parameters(), clip_value=50.0)\n","        optimizer.step()\n","        train_loss += loss.item()\n","\n","\n","        train_label_numpy = train_label.cpu().numpy()\n","        if probToPixel is None:\n","            # 未使用分类问题\n","            output_numpy = np.clip(output.detach().cpu().numpy(), 0.0, 1.0)\n","        else:\n","            # if classification, output: S*B*C*H*W\n","            # 使用分类问题，需要转化为像素值\n","            # 使用分类 Loss 的阈值\n","            output_numpy = probToPixel(output.detach().cpu().numpy(), train_label, mask,\n","                                                            lr_scheduler.get_lr()[0])\n","\n","        evaluater.update(train_label_numpy, output_numpy, mask.cpu().numpy())\n","\n","        if itera % test_iteration_interval == 0:\n","            _, _, train_csi, train_hss, _, train_mse, train_mae, train_balanced_mse, train_balanced_mae, _ = evaluater.calculate_stat()\n","\n","            train_loss = train_loss/test_iteration_interval\n","\n","            evaluater.clear_all()\n","\n","            with torch.no_grad():\n","                encoder_forecaster.eval()\n","                valid_hko_iter.reset()\n","                valid_loss = 0.0\n","                valid_time = 0\n","                while not valid_hko_iter.use_up:\n","                    valid_batch, valid_mask, sample_datetimes, _ = \\\n","                        valid_hko_iter.sample(batch_size=batch_size)\n","                    if valid_batch.shape[1] == 0:\n","                        break\n","                    if not cfg.HKO.EVALUATION.VALID_DATA_USE_UP and valid_time > cfg.HKO.EVALUATION.VALID_TIME:\n","                        break\n","                    valid_time += 1\n","                    valid_batch = torch.from_numpy(valid_batch.astype(np.float32)).to(cfg.GLOBAL.DEVICE) / 255.0\n","                    valid_data = valid_batch[:IN_LEN, ...]\n","                    valid_label = valid_batch[IN_LEN:IN_LEN + OUT_LEN, ...]\n","                    mask = torch.from_numpy(valid_mask[IN_LEN:IN_LEN + OUT_LEN, ...].astype(int)).to(cfg.GLOBAL.DEVICE)\n","                    output = encoder_forecaster(valid_data)\n","\n","                    loss = criterion(output, valid_label, mask)\n","                    valid_loss += loss.item()\n","\n","                    valid_label_numpy = valid_label.cpu().numpy()\n","                    if probToPixel is None:\n","                        output_numpy = np.clip(output.detach().cpu().numpy(), 0.0, 1.0)\n","                    else:\n","                        output_numpy = probToPixel(output.detach().cpu().numpy(), valid_label, mask, lr_scheduler.get_lr()[0])\n","\n","                    evaluater.update(valid_label_numpy, output_numpy, mask.cpu().numpy())\n","                _, _, valid_csi, valid_hss, _, valid_mse, valid_mae, valid_balanced_mse, valid_balanced_mae, _ = evaluater.calculate_stat()\n","\n","                evaluater.clear_all()\n","                valid_loss = valid_loss/valid_time\n","\n","            writer.add_scalars(\"loss\", {\n","                \"train\": train_loss,\n","                \"valid\": valid_loss\n","            }, itera)\n","\n","            plot_result(writer, itera, (train_csi, train_hss, train_mse, train_mae, train_balanced_mse, train_balanced_mae),\n","                        (valid_csi, valid_hss, valid_mse, valid_mae, valid_balanced_mse, valid_balanced_mae))\n","\n","            writer.export_scalars_to_json(all_scalars_file_name)\n","\n","            train_loss = 0.0\n","\n","        if itera % test_and_save_checkpoint_iterations == 0:\n","            torch.save(encoder_forecaster.state_dict(), osp.join(model_save_dir, 'encoder_forecaster_{}.pth'.format(itera)))\n","\n","    writer.close()\n"]}]}